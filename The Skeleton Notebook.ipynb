{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Skeleton Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the name suggests, this notebook/template serves as a great starting point for most Supervised Machine Learning projects that involve common tasks such as data exploration, cleaning, transformation and preparation, and data modelling (using machine learning or deep learning techniques).\n",
    "\n",
    "I've tried to build the notebook to provide a set workflow in which to handle the above tasks. These are arranged in sections, encouraged to be expanded to into sub-sections to handle approproate tasks. I've also tried to include common sub-tasks, and the code required to do them (usually Pandas or scikit-learn). \n",
    "\n",
    "Sections included:\n",
    "\n",
    "- Housekeeping and Imports\n",
    "- Data Loading\n",
    "- Data Exploration\n",
    "- Data Cleaning\n",
    "- Feature Engineering\n",
    "- Data Transformation and Preparation\n",
    "- Model Exploration and Performance Analysis\n",
    "- Final Model Building\n",
    "\n",
    "It is suggested to use separate notebooks if any of the above tasks are performed in depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For importing libraries necessary for the project, and for basic preprocessing functions (ex: typset conversion for NLP projects). \n",
    "\n",
    "We're going to import commonly used Data Science libraries, so make sure they're available for your Python set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for projects\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "# Import visualisation libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Make division futuristic for Python 2\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cell for Housekeeping code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading data files into appropriate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading the data file (ex: csv) using Pandas\n",
    "# data = pd.read_csv('') #insert path to file\n",
    "\n",
    "#Next steps?:\n",
    "# Loading the test data?\n",
    "# Loading the feaure vectors (X) and the prediction vector (Y) into different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section for **exploratory analysis** on the available data. \n",
    "\n",
    "The exploration techniques vary for numerical, categorical, or time-series variables. Currently, \n",
    "\n",
    "Here we typically:\n",
    "\n",
    "- look at example records in the dataset\n",
    "- investigate the datatypes of variables in the dataset\n",
    "- calculate and investigate descriptive statistics (ex: central tendencies, variability etc.)\n",
    "- investigate distribution of feature vectors (ex: to check for skewness and outliers)\n",
    "- investigate distribution of prediction vector\n",
    "- check out the relationship (ex: correlation) between different features\n",
    "- check out the relationship between feature vectors and prediction vector\n",
    "\n",
    "Common steps to check the health of the data:\n",
    "\n",
    "- Check for missing data\n",
    "- Check the skewness of the data, outlier detection\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Example Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.head(5) #Display out the first 5 records\n",
    "\n",
    "# Additional:\n",
    "#     Look at last few records using data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-types, completeness Information\n",
    "\n",
    "Using the Pandas \"info\" function, in addition to the data-type information for the dataset, we can look at counts of available records/missing records too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.describe()\n",
    "\n",
    "# Additonal: \n",
    "#     We can also make a guess at the skewness of the data at this stage by looking at the difference between\n",
    "#     the means and medians of numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualizaton: Distribution of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Section has great potential for expansion.* \n",
    "\n",
    "Visualization techniques differ depending on the type of the feature vector (i.e. numerical: continuous or discrete, categorical: ordinal etc). Techniques will also depend on the type of data being dealt with, and the insight that we want to extract from it. \n",
    "\n",
    "Common visualization techniques include:\n",
    "- Bar Plots: Visualize the frequency distribution of categorical features.\n",
    "- Histograms: Visualize the frequency distribution of numerical features.\n",
    "- Box Plots: Visualize a numerical feature, while providing more information like the median, lower/upper quantiles etc..\n",
    "- Scatter Plots: Visualize the relationship (usually the correlation) between two features. Can include a goodness of fit line, to serve as a regression plot.\n",
    "\n",
    "Below are example code snippets to draw these using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example: drawing a seaborn barplot\n",
    "#sns.barplot(x=\"\",y=\"\",hue=\"\",data=\"\")\n",
    "\n",
    "#Can also use pandas/matplotlib for histograms (numerical features) or barplots ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example: drawing a seaborn regplot\n",
    "# sns.regplot(data[feature1],data[feature2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example: drawing a pandas scatter_matrix\n",
    "# pd.scatter_matrix(data, alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating correlations between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing prediction vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of outliers can often skew results which take into consideration these data points. \n",
    "\n",
    "One approach to detect outliers is to use Tukey's Method for identfying them: An outlier step is calculated as 1.5 times the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal.\n",
    "\n",
    "One such pipeline for detecting outliers is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def find_outliers(data):\n",
    "\n",
    "#     #Checking for outliers that occur for more than one feature\n",
    "#     outliers  = []\n",
    "\n",
    "#     # For each feature find the data points with extreme high or low values\n",
    "#     for feature in [list of features to investigate]:\n",
    "\n",
    "#         # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "#         Q1 = np.percentile(data[feature],25)\n",
    "\n",
    "#         # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "#         Q3 = np.percentile(data[feature],75)\n",
    "\n",
    "#         # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "#         step = (Q3-Q1) * 1.5\n",
    "\n",
    "#         # Display the outliers\n",
    "#         out = data[~((data[feature] >= Q1 - step) & (data[feature] <= Q3 + step))]\n",
    "#         print \"Number of outliers for the feature '{}': {}\".format(feature, len(out))\n",
    "#         outliers = outliers + list(out.index.values)\n",
    "\n",
    "\n",
    "#     #Creating list of more outliers which are the same for multiple features.\n",
    "#     outliers = list(set([x for x in outliers if outliers.count(x) > 1])) \n",
    "    \n",
    "#     return outliers\n",
    "    \n",
    "# print \"Data points considered outliers for more than one feature: {}\".format(find_outliers(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning outliers or error values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the outliers, if any were specified \n",
    "# good_data = data.drop(data.index[outliers]).reset_index(drop = True)\n",
    "# print \"The good dataset now has {} observations after removing outliers.\".format(len(good_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section to extract more features from those currently available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Skewed Continous Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common practice to apply a logarthmic transformation to highly skewed continuous feature distributions. A typical flow for this is in a commented code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skewered = [list of skewed continuous features]\n",
    "# raw_features[skewed] = data[skewed].apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Numerical Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common practice is to perform some type of scaling on numerical features. Applying scaling doesn't change the shape of each feature's distribution; but ensures that each feature is treated equally when applying supervised learners. An example workflow of achieving normalisation using the MinMaxScaler module of sklearn is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# numerical = [list of skewed numerical features]\n",
    "# raw_features[numerical] = scaler.fit_transform(data[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking examples after transformation\n",
    "# raw_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Pandas get_dummies function\n",
    "# features = pd.get_dummies(raw_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encoding categorical prediction vector to numerical ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is encouraged to create a pipeline function for data preprocessing, rather than separate script blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, prediction_vector, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "# print \"Training set has {} samples.\".format(X_train.shape[0])\n",
    "# print \"Testing set has {} samples.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Predictor Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set a baseline for the performance of the predictor. \n",
    "\n",
    "Common techniques:\n",
    "- For categorical prediction vector, choose the most common class\n",
    "- For numerical prediction vector, choose a measure of central tendency\n",
    "\n",
    "Then calculate the evalation metric (accuracy, f-score etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code to implement the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training and Prediction Pipeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing models from sklearn, or tensorflow/keras components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change below as seen fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "#     '''\n",
    "#     inputs:\n",
    "#        - learner: the learning algorithm to be trained and predicted on\n",
    "#        - sample_size: the size of samples (number) to be drawn from training set\n",
    "#        - X_train: features training set\n",
    "#        - y_train: income training set\n",
    "#        - X_test: features testing set\n",
    "#        - y_test: income testing set\n",
    "#     '''\n",
    "    \n",
    "#     results = {}\n",
    "    \n",
    "#     # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "#     start = time() # Get start time\n",
    "#     learner = learner.fit(X_train[:sample_size],y_train[:sample_size])\n",
    "#     end = time() # Get end time\n",
    "    \n",
    "#     # TODO: Calculate the training time\n",
    "#     results['train_time'] = end - start\n",
    "        \n",
    "#     # TODO: Get the predictions on the test set,\n",
    "#     #       then get predictions on the first 300 training samples\n",
    "#     start = time() # Get start time\n",
    "#     predictions_test = learner.predict(X_test)\n",
    "#     predictions_train = learner.predict(X_train[:300])\n",
    "#     end = time() # Get end time\n",
    "    \n",
    "#     # TODO: Calculate the total prediction time\n",
    "#     results['pred_time'] = end - start\n",
    "            \n",
    "#     # TODO: Compute accuracy on the first 300 training samples\n",
    "#     results['acc_train'] = accuracy_score(y_train[:300],predictions_train)\n",
    "        \n",
    "#     # TODO: Compute accuracy on test set\n",
    "#     results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "#     # TODO: Compute F-score on the the first 300 training samples\n",
    "#     results['f_train'] = fbeta_score(y_train[:300],predictions_train,0.5)\n",
    "        \n",
    "#     # TODO: Compute F-score on the test set\n",
    "#     results['f_test'] = fbeta_score(y_test,predictions_test,0.5)\n",
    "       \n",
    "#     # Success\n",
    "#     print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
    "        \n",
    "#     # Return the results\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change the list of classifiers and code below as seen fit. we probably also don't need to see the effects of\n",
    "# different sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TODO: Import the three supervised learning models from sklearn\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# # TODO: Initialize the three models, the random states are set to 101 so we know how to reproduce the model later\n",
    "# clf_A = DecisionTreeClassifier(random_state=101)\n",
    "# clf_B = SVC(random_state = 101)\n",
    "# clf_C = AdaBoostClassifier(random_state = 101)\n",
    "\n",
    "# # TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "# samples_1 = int(round(len(X_train) / 100))\n",
    "# samples_10 = int(round(len(X_train) / 10))\n",
    "# samples_100 = len(X_train)\n",
    "\n",
    "# # Collect results on the learners in a dictionary\n",
    "# results = {}\n",
    "# for clf in [clf_A, clf_B, clf_C]:\n",
    "#     clf_name = clf.__class__.__name__\n",
    "#     results[clf_name] = {}\n",
    "#     for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
    "#         results[clf_name][i] = \\\n",
    "#         train_predict(clf, samples, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Printing out the values\n",
    "# for i in results.items():\n",
    "#     print i[0]\n",
    "#     display(pd.DataFrame(i[1]).rename(columns={0:'1%', 1:'10%', 2:'100%'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using grid search (GridSearchCV) with different parameter/value combinations, we can tune our model for even better results.\n",
    "\n",
    "Example with Adaboost below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer\n",
    "\n",
    "# # TODO: Initialize the classifier\n",
    "# clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "# # TODO: Create the parameters list you wish to tune\n",
    "# parameters = {'n_estimators':[50, 120], \n",
    "#               'learning_rate':[0.1, 0.5, 1.],\n",
    "#               'base_estimator__min_samples_split' : np.arange(2, 8, 2),\n",
    "#               'base_estimator__max_depth' : np.arange(1, 4, 1)\n",
    "#              }\n",
    "\n",
    "# # TODO: Make an fbeta_score scoring object\n",
    "# scorer = make_scorer(fbeta_score,beta=0.5)\n",
    "\n",
    "# # TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "# grid_obj = GridSearchCV(clf, parameters,scorer)\n",
    "\n",
    "# # TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "# grid_fit = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "# # Get the estimator\n",
    "# best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# # Make predictions using the unoptimized and model\n",
    "# predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "# best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# # Report the before-and-afterscores\n",
    "# print \"Unoptimized model\\n------\"\n",
    "# print \"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions))\n",
    "# print \"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5))\n",
    "# print \"\\nOptimized Model\\n------\"\n",
    "# print \"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions))\n",
    "# print \"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5))\n",
    "# print best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps can include feature importance extraction, predictions on the test set.. etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
